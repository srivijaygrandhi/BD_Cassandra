{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JueMQoHdjTRn",
        "outputId": "bdf4a27f-c8aa-4ffc-e94f-5d43a2725fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cassandra-driver in /usr/local/lib/python3.10/dist-packages (3.29.2)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver) (0.2.1.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 790f50dd-cfdf-41df-8870-e1e8346adb01-westus3.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 790f50dd-cfdf-41df-8870-e1e8346adb01-westus3.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 790f50dd-cfdf-41df-8870-e1e8346adb01-westus3.db.astra.datastax.com:29042:0750e59f-441b-37bb-b0a7-e097c5d725f7. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully connected to Cassandra!\n",
            "✅ Connected to keyspace: cass_keyspace\n",
            "🔍 Checking existing tables in the keyspace:\n",
            "- monthly_sales_summary\n",
            "- sales_bronze\n",
            "- sales_by_item_type\n",
            "- sales_by_region\n",
            "- sales_silver\n",
            "🗑️ Table 'monthly_sales_summary' dropped.\n",
            "🗑️ Table 'sales_bronze' dropped.\n",
            "🗑️ Table 'sales_by_item_type' dropped.\n",
            "🗑️ Table 'sales_by_region' dropped.\n",
            "🗑️ Table 'sales_silver' dropped.\n",
            "\n",
            "🟤 Creating the Bronze table, which stores raw data...\n",
            "🟤 Bronze table 'sales_bronze' created successfully!\n",
            "\n",
            "🟤 Inserting raw data into the Bronze table...\n",
            "✅ Data inserted into Bronze table 'sales_bronze'.\n",
            "\n",
            "🔘 Creating the Silver table, which stores cleaned and filtered data...\n",
            "🔘 Silver table 'sales_silver' created successfully!\n",
            "\n",
            "🔘 Inserting cleaned and filtered data into the Silver table...\n",
            "✅ Data inserted into Silver table 'sales_silver'.\n",
            "\n",
            "🟡 Creating Gold tables, which store aggregated data for analysis...\n",
            "🟡 Gold table 'sales_by_region' created.\n",
            "✅ Data inserted into Gold table 'sales_by_region'.\n",
            "🟡 Gold table 'sales_by_item_type' created.\n",
            "✅ Data inserted into Gold table 'sales_by_item_type'.\n",
            "🟡 Gold table 'monthly_sales_summary' created.\n",
            "✅ Data inserted into Gold table 'monthly_sales_summary'.\n",
            "\n",
            "📊 Querying the Gold tables for aggregated data:\n",
            "\n",
            "📋 Data from sales_by_region:\n",
            "Row(region='Australia and Oceania', total_profit=3486940.0)\n",
            "Row(region='Europe', total_profit=11267281.0)\n",
            "Row(region='Middle East and North Africa', total_profit=6514262.0)\n",
            "Row(region='Central America and the Caribbean', total_profit=4252300.0)\n",
            "Row(region='Asia', total_profit=6749896.0)\n",
            "Row(region='Sub-Saharan Africa', total_profit=7651892.0)\n",
            "Row(region='North America', total_profit=1404621.5)\n",
            "\n",
            "📋 Data from sales_by_item_type:\n",
            "Row(item_type='Household', total_units_sold=57640)\n",
            "Row(item_type='Office Supplies', total_units_sold=42814)\n",
            "Row(item_type='Vegetables', total_units_sold=7368)\n",
            "Row(item_type='Snacks', total_units_sold=14377)\n",
            "Row(item_type='Personal Care', total_units_sold=39045)\n",
            "Row(item_type='Meat', total_units_sold=50437)\n",
            "Row(item_type='Fruits', total_units_sold=65920)\n",
            "Row(item_type='Beverages', total_units_sold=45206)\n",
            "Row(item_type='Cereal', total_units_sold=45776)\n",
            "Row(item_type='Cosmetics', total_units_sold=65707)\n",
            "Row(item_type='Baby Food', total_units_sold=20372)\n",
            "Row(item_type='Clothes', total_units_sold=40148)\n",
            "\n",
            "📋 Data from monthly_sales_summary:\n",
            "Row(order_date='7/1/2012', total_revenue=1071140.0)\n",
            "Row(order_date='9/5/2012', total_revenue=56530.46875)\n",
            "Row(order_date='2/4/2015', total_revenue=1856737.875)\n",
            "Row(order_date='1/27/2013', total_revenue=34856.87890625)\n",
            "Row(order_date='10/11/2012', total_revenue=274640.59375)\n",
            "Row(order_date='11/7/2011', total_revenue=12866.0703125)\n",
            "Row(order_date='5/17/2017', total_revenue=61415.359375)\n",
            "Row(order_date='1/19/2011', total_revenue=746767.0)\n",
            "Row(order_date='1/15/2016', total_revenue=5445064.0)\n",
            "Row(order_date='4/11/2010', total_revenue=1932962.875)\n",
            "Row(order_date='11/19/2011', total_revenue=4707294.0)\n",
            "Row(order_date='9/8/2015', total_revenue=2101183.25)\n",
            "Row(order_date='7/29/2014', total_revenue=3672173.25)\n",
            "Row(order_date='5/11/2016', total_revenue=1411953.625)\n",
            "Row(order_date='6/20/2014', total_revenue=1168581.75)\n",
            "Row(order_date='12/5/2016', total_revenue=3780403.5)\n",
            "Row(order_date='10/17/2016', total_revenue=339860.8125)\n",
            "Row(order_date='11/11/2015', total_revenue=301612.8125)\n",
            "Row(order_date='10/22/2012', total_revenue=760579.375)\n",
            "Row(order_date='11/13/2014', total_revenue=434357.3125)\n",
            "Row(order_date='11/1/2011', total_revenue=231050.703125)\n",
            "Row(order_date='2/21/2014', total_revenue=4006267.5)\n",
            "Row(order_date='3/23/2017', total_revenue=583484.1875)\n",
            "Row(order_date='10/20/2014', total_revenue=89558.671875)\n",
            "Row(order_date='11/2/2011', total_revenue=419198.09375)\n",
            "Row(order_date='12/7/2015', total_revenue=2570673.75)\n",
            "Row(order_date='3/16/2016', total_revenue=3012716.5)\n",
            "Row(order_date='9/28/2011', total_revenue=416332.21875)\n",
            "Row(order_date='2/10/2016', total_revenue=3771157.0)\n",
            "Row(order_date='5/23/2016', total_revenue=3396169.5)\n",
            "Row(order_date='8/19/2010', total_revenue=2884921.5)\n",
            "Row(order_date='3/1/2016', total_revenue=2149107.75)\n",
            "Row(order_date='6/14/2015', total_revenue=288752.09375)\n",
            "Row(order_date='11/30/2016', total_revenue=70036.203125)\n",
            "Row(order_date='1/18/2013', total_revenue=28327.650390625)\n",
            "Row(order_date='3/29/2011', total_revenue=1896974.75)\n",
            "Row(order_date='4/13/2015', total_revenue=1027580.1875)\n",
            "Row(order_date='5/9/2011', total_revenue=3263260.75)\n",
            "Row(order_date='11/29/2010', total_revenue=3470056.5)\n",
            "Row(order_date='7/7/2011', total_revenue=289426.40625)\n",
            "Row(order_date='6/23/2012', total_revenue=6253569.5)\n",
            "Row(order_date='10/9/2012', total_revenue=107533.8828125)\n",
            "Row(order_date='6/18/2010', total_revenue=44224.19921875)\n",
            "Row(order_date='3/8/2017', total_revenue=3699975.25)\n",
            "Row(order_date='10/28/2015', total_revenue=5206491.5)\n",
            "Row(order_date='4/4/2010', total_revenue=652532.3125)\n",
            "Row(order_date='9/4/2016', total_revenue=231345.765625)\n",
            "Row(order_date='6/12/2012', total_revenue=298982.4375)\n",
            "Row(order_date='11/15/2011', total_revenue=1456356.0)\n",
            "Row(order_date='7/6/2016', total_revenue=802989.4375)\n",
            "Row(order_date='2/6/2016', total_revenue=126109.390625)\n",
            "Row(order_date='2/19/2012', total_revenue=217368.453125)\n",
            "Row(order_date='4/30/2017', total_revenue=2196359.25)\n",
            "Row(order_date='9/30/2012', total_revenue=14508.150390625)\n",
            "Row(order_date='5/15/2015', total_revenue=151880.40625)\n",
            "Row(order_date='9/1/2011', total_revenue=6666661.5)\n",
            "Row(order_date='10/2/2011', total_revenue=4100669.25)\n",
            "Row(order_date='1/28/2013', total_revenue=1171204.125)\n",
            "Row(order_date='9/14/2013', total_revenue=503890.09375)\n",
            "Row(order_date='6/20/2011', total_revenue=993573.75)\n",
            "Row(order_date='2/18/2011', total_revenue=4227287.0)\n",
            "Row(order_date='11/17/2012', total_revenue=603225.625)\n",
            "Row(order_date='8/25/2011', total_revenue=69946.71875)\n",
            "Row(order_date='11/20/2011', total_revenue=81161.671875)\n",
            "Row(order_date='1/21/2016', total_revenue=348496.71875)\n",
            "Row(order_date='6/6/2015', total_revenue=337990.71875)\n",
            "Row(order_date='6/13/2011', total_revenue=979683.8125)\n",
            "Row(order_date='2/9/2014', total_revenue=74957.21875)\n",
            "Row(order_date='7/16/2014', total_revenue=5608790.0)\n",
            "Row(order_date='12/31/2010', total_revenue=1336282.875)\n",
            "Row(order_date='11/3/2013', total_revenue=53507.55078125)\n",
            "Row(order_date='3/28/2011', total_revenue=6266594.0)\n",
            "Row(order_date='10/26/2016', total_revenue=188518.84375)\n",
            "Row(order_date='9/8/2013', total_revenue=429730.1875)\n",
            "Row(order_date='10/10/2012', total_revenue=816150.4375)\n",
            "Row(order_date='3/22/2014', total_revenue=4003440.5)\n",
            "Row(order_date='6/19/2014', total_revenue=36860.23046875)\n",
            "Row(order_date='9/13/2012', total_revenue=117913.25)\n",
            "Row(order_date='7/19/2012', total_revenue=2014159.25)\n",
            "Row(order_date='12/12/2015', total_revenue=33410.73046875)\n",
            "Row(order_date='12/17/2010', total_revenue=2823440.75)\n",
            "Row(order_date='3/9/2011', total_revenue=167640.84375)\n",
            "Row(order_date='4/16/2015', total_revenue=1509220.875)\n",
            "Row(order_date='2/28/2015', total_revenue=2636753.25)\n",
            "Row(order_date='11/30/2015', total_revenue=643018.1875)\n",
            "Row(order_date='11/11/2016', total_revenue=738014.5)\n",
            "Row(order_date='5/1/2015', total_revenue=453813.59375)\n",
            "Row(order_date='7/27/2012', total_revenue=14862.6904296875)\n",
            "Row(order_date='5/29/2016', total_revenue=136140.640625)\n",
            "Row(order_date='11/19/2016', total_revenue=92245.7109375)\n",
            "Row(order_date='8/22/2015', total_revenue=1784241.75)\n",
            "Row(order_date='10/2/2010', total_revenue=628499.375)\n",
            "Row(order_date='10/7/2012', total_revenue=1297172.375)\n",
            "Row(order_date='8/9/2016', total_revenue=130261.7578125)\n",
            "Row(order_date='12/28/2013', total_revenue=4205821.5)\n",
            "Row(order_date='5/28/2013', total_revenue=868465.375)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary library\n",
        "!pip install cassandra-driver\n",
        "\n",
        "# Import required libraries\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import json\n",
        "\n",
        "# Load secure connect bundle for Cassandra\n",
        "cloud_config = {\n",
        "    'secure_connect_bundle': 'secure-connect-big-data-cassandra.zip'  # Replace with your secure connect bundle\n",
        "}\n",
        "with open(\"grandh23@students.rowan.edu-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "# Verifying connection\n",
        "if session:\n",
        "    print(\"✅ Successfully connected to Cassandra!\")\n",
        "else:\n",
        "    print(\"❌ An error occurred while connecting.\")\n",
        "\n",
        "# Setting keyspace\n",
        "keyspace_name = 'cass_keyspace'\n",
        "session.set_keyspace(keyspace_name)\n",
        "print(f\"✅ Connected to keyspace: {session.keyspace}\")\n",
        "\n",
        "# Checking for existing tables\n",
        "rows = session.execute(f\"SELECT table_name FROM system_schema.tables WHERE keyspace_name = '{keyspace_name}'\")\n",
        "print(\"🔍 Checking existing tables in the keyspace:\")\n",
        "for row in rows:\n",
        "    print(f\"- {row.table_name}\")\n",
        "\n",
        "# Dropping existing tables\n",
        "rows = session.execute(f\"SELECT table_name FROM system_schema.tables WHERE keyspace_name = '{keyspace_name}'\")\n",
        "for row in rows:\n",
        "    table_name = row.table_name\n",
        "    try:\n",
        "        session.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
        "        print(f\"🗑️ Table '{table_name}' dropped.\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error dropping table '{table_name}': {e}\")\n",
        "\n",
        "# Step 1: Create Bronze Table\n",
        "print(\"\\n🟤 Creating the Bronze table, which stores raw data...\")\n",
        "session.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS sales_bronze (\n",
        "    region TEXT,\n",
        "    country TEXT,\n",
        "    item_type TEXT,\n",
        "    sales_channel TEXT,\n",
        "    order_priority TEXT,\n",
        "    order_date TEXT,\n",
        "    order_id UUID PRIMARY KEY,\n",
        "    ship_date TEXT,\n",
        "    units_sold INT,\n",
        "    unit_price FLOAT,\n",
        "    unit_cost FLOAT,\n",
        "    total_revenue FLOAT,\n",
        "    total_cost FLOAT,\n",
        "    total_profit FLOAT\n",
        ");\n",
        "\"\"\")\n",
        "print(\"🟤 Bronze table 'sales_bronze' created successfully!\")\n",
        "\n",
        "# Step 2: Load data into Bronze Table\n",
        "print(\"\\n🟤 Inserting raw data into the Bronze table...\")\n",
        "df = pd.read_csv('/content/sales_100.csv')  # Replace with the correct path to your CSV file\n",
        "for _, row in df.iterrows():\n",
        "    session.execute(\"\"\"\n",
        "        INSERT INTO sales_bronze (region, country, item_type, sales_channel, order_priority, order_date, order_id, ship_date, units_sold, unit_price, unit_cost, total_revenue, total_cost, total_profit)\n",
        "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
        "    \"\"\", (\n",
        "        row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n",
        "        row['Order Priority'], row['Order Date'], uuid.uuid4(),\n",
        "        row['Ship Date'], row['UnitsSold'], row['UnitPrice'],\n",
        "        row['UnitCost'], row['TotalRevenue'], row['TotalCost'], row['TotalProfit']\n",
        "    ))\n",
        "print(\"✅ Data inserted into Bronze table 'sales_bronze'.\")\n",
        "\n",
        "# Step 3: Create Silver Table\n",
        "print(\"\\n🔘 Creating the Silver table, which stores cleaned and filtered data...\")\n",
        "session.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS sales_silver (\n",
        "    order_id UUID PRIMARY KEY,\n",
        "    region TEXT,\n",
        "    country TEXT,\n",
        "    item_type TEXT,\n",
        "    total_profit FLOAT\n",
        ");\n",
        "\"\"\")\n",
        "print(\"🔘 Silver table 'sales_silver' created successfully!\")\n",
        "\n",
        "# Populate Silver Table\n",
        "print(\"\\n🔘 Inserting cleaned and filtered data into the Silver table...\")\n",
        "rows = session.execute(\"SELECT order_id, region, country, item_type, total_profit FROM sales_bronze;\")\n",
        "for row in rows:\n",
        "    session.execute(\"\"\"\n",
        "        INSERT INTO sales_silver (order_id, region, country, item_type, total_profit)\n",
        "        VALUES (%s, %s, %s, %s, %s)\n",
        "    \"\"\", (row.order_id, row.region, row.country, row.item_type, row.total_profit))\n",
        "print(\"✅ Data inserted into Silver table 'sales_silver'.\")\n",
        "\n",
        "# Step 4: Create and Populate Gold Tables\n",
        "print(\"\\n🟡 Creating Gold tables, which store aggregated data for analysis...\")\n",
        "\n",
        "# Table: Sales by Region\n",
        "session.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS sales_by_region (\n",
        "    region TEXT PRIMARY KEY,\n",
        "    total_profit FLOAT\n",
        ");\n",
        "\"\"\")\n",
        "print(\"🟡 Gold table 'sales_by_region' created.\")\n",
        "\n",
        "rows = session.execute(\"SELECT region, total_profit FROM sales_bronze\")\n",
        "df_region = pd.DataFrame(rows)\n",
        "aggregated_region = df_region.groupby('region', as_index=False).agg({'total_profit': 'sum'})\n",
        "for _, row in aggregated_region.iterrows():\n",
        "    session.execute(\"\"\"\n",
        "        INSERT INTO sales_by_region (region, total_profit)\n",
        "        VALUES (%s, %s)\n",
        "    \"\"\", (row['region'], row['total_profit']))\n",
        "print(\"✅ Data inserted into Gold table 'sales_by_region'.\")\n",
        "\n",
        "# Table: Sales by Item Type\n",
        "session.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS sales_by_item_type (\n",
        "    item_type TEXT PRIMARY KEY,\n",
        "    total_units_sold INT\n",
        ");\n",
        "\"\"\")\n",
        "print(\"🟡 Gold table 'sales_by_item_type' created.\")\n",
        "\n",
        "rows = session.execute(\"SELECT item_type, units_sold FROM sales_bronze\")\n",
        "df_item_type = pd.DataFrame(rows)\n",
        "aggregated_item_type = df_item_type.groupby('item_type', as_index=False).agg({'units_sold': 'sum'})\n",
        "for _, row in aggregated_item_type.iterrows():\n",
        "    session.execute(\"\"\"\n",
        "        INSERT INTO sales_by_item_type (item_type, total_units_sold)\n",
        "        VALUES (%s, %s)\n",
        "    \"\"\", (row['item_type'], row['units_sold']))\n",
        "print(\"✅ Data inserted into Gold table 'sales_by_item_type'.\")\n",
        "\n",
        "# Table: Monthly Sales Summary\n",
        "session.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS monthly_sales_summary (\n",
        "    order_date TEXT PRIMARY KEY,\n",
        "    total_revenue FLOAT\n",
        ");\n",
        "\"\"\")\n",
        "print(\"🟡 Gold table 'monthly_sales_summary' created.\")\n",
        "\n",
        "rows = session.execute(\"SELECT order_date, total_revenue FROM sales_bronze\")\n",
        "df_order_date = pd.DataFrame(rows)\n",
        "aggregated_order_date = df_order_date.groupby('order_date', as_index=False).agg({'total_revenue': 'sum'})\n",
        "for _, row in aggregated_order_date.iterrows():\n",
        "    session.execute(\"\"\"\n",
        "        INSERT INTO monthly_sales_summary (order_date, total_revenue)\n",
        "        VALUES (%s, %s)\n",
        "    \"\"\", (row['order_date'], row['total_revenue']))\n",
        "print(\"✅ Data inserted into Gold table 'monthly_sales_summary'.\")\n",
        "\n",
        "# Step 5: Query Gold Tables\n",
        "print(\"\\n📊 Querying the Gold tables for aggregated data:\")\n",
        "gold_tables = [\"sales_by_region\", \"sales_by_item_type\", \"monthly_sales_summary\"]\n",
        "for table in gold_tables:\n",
        "    print(f\"\\n📋 Data from {table}:\")\n",
        "    rows = session.execute(f\"SELECT * FROM {table};\")\n",
        "    for row in rows:\n",
        "        print(row)\n"
      ]
    }
  ]
}